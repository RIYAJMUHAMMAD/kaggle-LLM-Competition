{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# How To Train Model for Open Book Q&A Technique\nIn this notebook we demonstrate how to train a model to be used with top scoring Open Book Q&A method. The Open Book method was first presented by JJ (@jjinho) [here][1], then Quangteo (@quangbk) improved RAM usage [here][2], and Anil (@nlztrk) combined with Q&A [here][3]. Radek (@radek1) demonstrated the strength of Q&A [here][5]. Next Mgoksu (@mgoksu) demonstrated how to achieve top public LB=0.807 using this method [here][4] by finetuning DeBerta large on this method.\n\nIn order to train a model for use with Open Book Q&A, we need a CSV that contains; `prompt` (i.e. question), `A, B, C, D, E` (i.e. answer choices), and we need a column of `context` extracted from wikipedia pages for each question. To generate the `context` column, we run Mgoksu's notebook [here][4]. In code cell #5, we load our CSV without `context` column with code `trn = pd.read_csv(OUR_DATASET.CSV)`. Then in code cell #21 our dataset is saved to disk as `test_context.csv` with the column `context` added.\n\nI have searched and concatenated all publicly shared datasets into one 60k CSV and then ran Mgoksu's notebook with `NUM_TITLES_INCLUDE = 5` and `NUM_SENTENCES_INCLUDE = 20`. This added an additional `context` column. I uploaded the resultant CSV file to a Kaggle dataset [here][6]. If you enjoy the notebook you are reading, please upvote the dataset too. Thanks! \n\n![](https://miro.medium.com/v2/resize:fit:800/format:webp/1*bTGY3fKIgNefQxNsOYpnBw.png)\n \n(image source [here][7])\n\n[1]: https://www.kaggle.com/code/jjinho/open-book-llm-science-exam\n[2]: https://www.kaggle.com/code/quangbk/open-book-llm-science-exam-reduced-ram-usage\n[3]: https://www.kaggle.com/code/nlztrk/openbook-debertav3-large-baseline-single-model\n[4]: https://www.kaggle.com/code/mgoksu/0-807-sharing-my-trained-with-context-model\n[5]: https://www.kaggle.com/code/radek1/new-dataset-deberta-v3-large-training\n[6]: https://www.kaggle.com/datasets/cdeotte/60k-data-with-context-v2\n[7]: https://blog.gopenai.com/enrich-llms-with-retrieval-augmented-generation-rag-17b82a96b6f0","metadata":{}},{"cell_type":"markdown","source":"# Load CSV\nWe will load 60k CSV of `prompts`, `A,B,C,D,E`, and `context` from my Kaggle dataset [here][1]. This dataset is all publicly shared datasets concatenated then processed with Mgoksu's notebook [here][2] to create a `context` column. (To learn more about the datasets within read my discussion post). This Kaggle dataset also contains competition `train.csv` with added `context` column (to be used as a validation dataset).\n\nIn this train notebook, we have internet turned on and can choose whatever model we wish to download and train. After we finetune this model, we will create a second notebook with the Open Book Q&A technique and load the finetuned model from the output of this notebook. The second notebook will have internet turned off so that it can be submitted to Kaggle's competition.\n\n[1]: https://www.kaggle.com/datasets/cdeotte/60k-data-with-context-v2\n[2]: https://www.kaggle.com/code/mgoksu/0-807-sharing-my-trained-with-context-model","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n\nfrom typing import Optional, Union\nimport pandas as pd, numpy as np, torch\nfrom datasets import Dataset\nfrom dataclasses import dataclass\nfrom transformers import AutoTokenizer\nfrom transformers import EarlyStoppingCallback\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n\nVER=2\n# TRAIN WITH SUBSET OF 60K\nNUM_TRAIN_SAMPLES = 8000\n# PARAMETER EFFICIENT FINE TUNING\n# PEFT REQUIRES 1XP100 GPU NOT 2XT4\nUSE_PEFT = False\n# NUMBER OF LAYERS TO FREEZE \n# DEBERTA LARGE HAS TOTAL OF 24 LAYERS\nFREEZE_LAYERS = 0\n# BOOLEAN TO FREEZE EMBEDDINGS\nFREEZE_EMBEDDINGS = True\n# LENGTH OF CONTEXT PLUS QUESTION ANSWER\nMAX_INPUT = 384\n# HUGGING FACE MODEL\nMODEL = '/kaggle/input/fork-of-fork-of-fork-of-fork-of-fork-of-for-6f9e68/checkpoints_2/checkpoint-75'\ntorch.manual_seed(786)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T10:58:22.433437Z","iopub.execute_input":"2023-09-26T10:58:22.433800Z","iopub.status.idle":"2023-09-26T10:58:38.088438Z","shell.execute_reply.started":"2023-09-26T10:58:22.433739Z","shell.execute_reply":"2023-09-26T10:58:38.087497Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7cf543476e90>"},"metadata":{}}]},{"cell_type":"code","source":"df_te = pd.read_csv('/kaggle/input/60k-data-with-context-v2/train_with_context2.csv')\nprint('Validation data size:', df_te.shape )\ndf_te.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T10:58:38.090291Z","iopub.execute_input":"2023-09-26T10:58:38.090733Z","iopub.status.idle":"2023-09-26T10:58:38.155950Z","shell.execute_reply.started":"2023-09-26T10:58:38.090699Z","shell.execute_reply":"2023-09-26T10:58:38.154958Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Validation data size: (200, 8)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  Which of the following statements accurately d...   \n1  Which of the following is an accurate definiti...   \n2  Which of the following statements accurately d...   \n3  What is the significance of regularization in ...   \n4  Which of the following statements accurately d...   \n\n                                             context  \\\n0  The presence of a clustered thick disk-like co...   \n1  Many of these systems evolve in a self-similar...   \n2  It is possible that this usage is related with...   \n3  Renormalization is distinct from regularizatio...   \n4  Several qualitative observations can be made o...   \n\n                                                   A  \\\n0  MOND is a theory that reduces the observed mis...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol was reconstructed as a fe...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   B  \\\n0  MOND is a theory that increases the discrepanc...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol is a representation of th...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   C  \\\n0  MOND is a theory that explains the missing bar...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol is a representation of a ...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   D  \\\n0  MOND is a theory that reduces the discrepancy ...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol represents three interloc...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   E answer  \n0  MOND is a theory that eliminates the observed ...      D  \n1  Dynamic scaling refers to the evolution of sel...      A  \n2  The triskeles symbol is a representation of th...      A  \n3  Regularizing the mass-energy of an electron wi...      C  \n4  The angular spacing of features in the diffrac...      D  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>context</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>The presence of a clustered thick disk-like co...</td>\n      <td>MOND is a theory that reduces the observed mis...</td>\n      <td>MOND is a theory that increases the discrepanc...</td>\n      <td>MOND is a theory that explains the missing bar...</td>\n      <td>MOND is a theory that reduces the discrepancy ...</td>\n      <td>MOND is a theory that eliminates the observed ...</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Which of the following is an accurate definiti...</td>\n      <td>Many of these systems evolve in a self-similar...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>It is possible that this usage is related with...</td>\n      <td>The triskeles symbol was reconstructed as a fe...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>The triskeles symbol is a representation of a ...</td>\n      <td>The triskeles symbol represents three interloc...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the significance of regularization in ...</td>\n      <td>Renormalization is distinct from regularizatio...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>Several qualitative observations can be made o...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>D</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_tr = pd.read_csv('/kaggle/input/60k-data-with-context-v2/all_12_with_context2.csv')\n#mask = ~df_tr.isin(df_te)\n#df_tr = df_tr[mask].dropna().drop_duplicates().reset_index(drop=True)\n# del df\ndf_tr.shape\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T10:58:38.157609Z","iopub.execute_input":"2023-09-26T10:58:38.158294Z","iopub.status.idle":"2023-09-26T10:58:46.555835Z","shell.execute_reply.started":"2023-09-26T10:58:38.158254Z","shell.execute_reply":"2023-09-26T10:58:46.554727Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(60347, 9)"},"metadata":{}}]},{"cell_type":"code","source":"df_tr = df_tr.drop(columns=\"source\")\ndf_tr = df_tr.fillna('')\ndf_train = df_tr.iloc[38200:42200, :]\ndf_valid = pd.concat([df_te, df_tr.iloc[59500:, :]])\nprint('Train data size:', df_train.shape )\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T10:58:46.558818Z","iopub.execute_input":"2023-09-26T10:58:46.559209Z","iopub.status.idle":"2023-09-26T10:58:46.667848Z","shell.execute_reply.started":"2023-09-26T10:58:46.559174Z","shell.execute_reply":"2023-09-26T10:58:46.666914Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Train data size: (4000, 8)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                  prompt  \\\n38200  Where is the gene responsible for directing th...   \n38201  What is the significance of rainbow gravity th...   \n38202        What is the purpose of the hole-board test?   \n38203            What is adaptive voltage scaling (AVS)?   \n38204  What type of wave does a Leaky-Wave Antenna ut...   \n\n                                                 context  \\\n38200  The TP receptor derives its name from its pref...   \n38201  Rainbow gravity (or \"gravity's rainbow\") is a ...   \n38202  The hole-board test (HBT) is an experimental m...   \n38203  Adaptive voltage scaling (AVS) is a closed-loo...   \n38204  Traveling-wave antenna fall into two general c...   \n\n                                                       A  \\\n38200                  On chromosome 19 at position p13.   \n38201  It causes different wavelengths of light to re...   \n38202  The hole-board test is used to measure anxiety...   \n38203  Adaptive voltage scaling is a closed-loop dyna...   \n38204  Leaky-Wave Antennas utilize standing waves wit...   \n\n                                                       B  \\\n38200                  On chromosome 13 at position p19.   \n38201  It causes different wavelengths of light to be...   \n38202  The hole-board test is used to measure anxiety...   \n38203  Adaptive voltage scaling is a closed-loop stat...   \n38204  Leaky-Wave Antennas utilize traveling waves wi...   \n\n                                                       C  \\\n38200                  On chromosome 19 at position q13.   \n38201  It causes different wavelengths of light to ex...   \n38202  The hole-board test is used to measure anxiety...   \n38203  Adaptive voltage scaling is an open-loop stati...   \n38204  Leaky-Wave Antennas utilize traveling waves wi...   \n\n                                                       D  \\\n38200                  On chromosome 17 at position p13.   \n38201  It causes different wavelengths of light to be...   \n38202  The hole-board test is used to measure anxiety...   \n38203  Adaptive voltage scaling is a closed-loop dyna...   \n38204  Leaky-Wave Antennas utilize stationary waves w...   \n\n                                                       E answer  \n38200                  On chromosome 13 at position q19.      A  \n38201  It causes different wavelengths of light to ex...      C  \n38202  The hole-board test is used to measure anxiety...      E  \n38203  Adaptive voltage scaling is an open-loop stati...      A  \n38204  Leaky-Wave Antennas utilize stationary waves w...      C  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>context</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>38200</th>\n      <td>Where is the gene responsible for directing th...</td>\n      <td>The TP receptor derives its name from its pref...</td>\n      <td>On chromosome 19 at position p13.</td>\n      <td>On chromosome 13 at position p19.</td>\n      <td>On chromosome 19 at position q13.</td>\n      <td>On chromosome 17 at position p13.</td>\n      <td>On chromosome 13 at position q19.</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>38201</th>\n      <td>What is the significance of rainbow gravity th...</td>\n      <td>Rainbow gravity (or \"gravity's rainbow\") is a ...</td>\n      <td>It causes different wavelengths of light to re...</td>\n      <td>It causes different wavelengths of light to be...</td>\n      <td>It causes different wavelengths of light to ex...</td>\n      <td>It causes different wavelengths of light to be...</td>\n      <td>It causes different wavelengths of light to ex...</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>38202</th>\n      <td>What is the purpose of the hole-board test?</td>\n      <td>The hole-board test (HBT) is an experimental m...</td>\n      <td>The hole-board test is used to measure anxiety...</td>\n      <td>The hole-board test is used to measure anxiety...</td>\n      <td>The hole-board test is used to measure anxiety...</td>\n      <td>The hole-board test is used to measure anxiety...</td>\n      <td>The hole-board test is used to measure anxiety...</td>\n      <td>E</td>\n    </tr>\n    <tr>\n      <th>38203</th>\n      <td>What is adaptive voltage scaling (AVS)?</td>\n      <td>Adaptive voltage scaling (AVS) is a closed-loo...</td>\n      <td>Adaptive voltage scaling is a closed-loop dyna...</td>\n      <td>Adaptive voltage scaling is a closed-loop stat...</td>\n      <td>Adaptive voltage scaling is an open-loop stati...</td>\n      <td>Adaptive voltage scaling is a closed-loop dyna...</td>\n      <td>Adaptive voltage scaling is an open-loop stati...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>38204</th>\n      <td>What type of wave does a Leaky-Wave Antenna ut...</td>\n      <td>Traveling-wave antenna fall into two general c...</td>\n      <td>Leaky-Wave Antennas utilize standing waves wit...</td>\n      <td>Leaky-Wave Antennas utilize traveling waves wi...</td>\n      <td>Leaky-Wave Antennas utilize traveling waves wi...</td>\n      <td>Leaky-Wave Antennas utilize stationary waves w...</td>\n      <td>Leaky-Wave Antennas utilize stationary waves w...</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Loader\nCode is from Radek's notebook [here][1] with modifications to the tokenization process.\n\n[1]: https://www.kaggle.com/code/radek1/new-dataset-deberta-v3-large-training","metadata":{}},{"cell_type":"code","source":"option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\nindex_to_option = {v: k for k,v in option_to_index.items()}\n\ndef preprocess(example):\n    first_sentence = [ \"[CLS] \" + example['context'] ] * 5\n    second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in 'ABCDE']\n    tokenized_example = tokenizer(first_sentence, second_sentences, truncation='only_first', \n                                  max_length=MAX_INPUT, add_special_tokens=False)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    \n    return tokenized_example\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"execution":{"iopub.status.busy":"2023-09-26T10:58:46.669550Z","iopub.execute_input":"2023-09-26T10:58:46.669932Z","iopub.status.idle":"2023-09-26T10:58:46.683450Z","shell.execute_reply.started":"2023-09-26T10:58:46.669897Z","shell.execute_reply":"2023-09-26T10:58:46.682202Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL)\ndataset_valid = Dataset.from_pandas(df_valid)\ndataset = Dataset.from_pandas(df_train)\n#dataset = dataset.remove_columns([\"__index_level_0__\"])\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-09-26T10:58:46.684945Z","iopub.execute_input":"2023-09-26T10:58:46.685380Z","iopub.status.idle":"2023-09-26T10:58:47.172286Z","shell.execute_reply.started":"2023-09-26T10:58:46.685330Z","shell.execute_reply":"2023-09-26T10:58:47.171316Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'],\n    num_rows: 4000\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_dataset_valid = dataset_valid.map(preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'])\ntokenized_dataset = dataset.map(preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'])\ntokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-26T10:58:47.173518Z","iopub.execute_input":"2023-09-26T10:58:47.173859Z","iopub.status.idle":"2023-09-26T11:00:28.697609Z","shell.execute_reply.started":"2023-09-26T10:58:47.173831Z","shell.execute_reply":"2023-09-26T11:00:28.696656Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1047 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4da220666e041ebae030989b7294239"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4000 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91f0fdb3412a4b9eb1f4fe1e49daca4e"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n    num_rows: 4000\n})"},"metadata":{}}]},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T11:00:28.698998Z","iopub.execute_input":"2023-09-26T11:00:28.699847Z","iopub.status.idle":"2023-09-26T11:00:28.947234Z","shell.execute_reply.started":"2023-09-26T11:00:28.699813Z","shell.execute_reply":"2023-09-26T11:00:28.946283Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"81"},"metadata":{}}]},{"cell_type":"markdown","source":"# Build Model\nWe will use a Hugging Face AutoModelForMultipleChoice. For the list of possible models, see Hugging Face's repository [here][1]. We can optionally use PEFT to accelerate training and use less memory. However i have noticed that validation accuracy is less. (Note that PEFT requires us to use 1xP100 not 2xT4 GPU. I'm not sure why). We can also optionally freeze layers. This also accelerates training and uses less memory. However validation accuracy may become less.\n\n[1]: https://huggingface.co/models","metadata":{}},{"cell_type":"code","source":"model = AutoModelForMultipleChoice.from_pretrained(MODEL)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T11:00:28.948565Z","iopub.execute_input":"2023-09-26T11:00:28.948987Z","iopub.status.idle":"2023-09-26T11:00:47.445598Z","shell.execute_reply.started":"2023-09-26T11:00:28.948952Z","shell.execute_reply":"2023-09-26T11:00:47.444506Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# NOTE PEFT REQUIRES US TO USE 1XP100 NOT 2XT4. I'M NOT SURE WHY.\nif USE_PEFT:\n    !pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-26T11:00:47.449647Z","iopub.execute_input":"2023-09-26T11:00:47.449938Z","iopub.status.idle":"2023-09-26T11:00:47.455304Z","shell.execute_reply.started":"2023-09-26T11:00:47.449913Z","shell.execute_reply":"2023-09-26T11:00:47.454288Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"if USE_PEFT:\n    print('We are using PEFT.')\n    from peft import LoraConfig, get_peft_model, TaskType\n    peft_config = LoraConfig(\n        r=8, lora_alpha=4, task_type=TaskType.SEQ_CLS, lora_dropout=0.1, \n        bias=\"none\", inference_mode=False, \n        target_modules=[\"query_proj\", \"value_proj\"],\n        modules_to_save=['classifier','pooler'],\n    )\n    model = get_peft_model(model, peft_config)\n    model.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T11:00:47.456816Z","iopub.execute_input":"2023-09-26T11:00:47.457426Z","iopub.status.idle":"2023-09-26T11:00:47.466507Z","shell.execute_reply.started":"2023-09-26T11:00:47.457392Z","shell.execute_reply":"2023-09-26T11:00:47.465539Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"if FREEZE_EMBEDDINGS:\n    print('Freezing embeddings.')\n    for param in model.deberta.embeddings.parameters():\n        param.requires_grad = False\nif FREEZE_LAYERS>0:\n    print(f'Freezing {FREEZE_LAYERS} layers.')\n    for layer in model.deberta.encoder.layer[:FREEZE_LAYERS]:\n        for param in layer.parameters():\n            param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2023-09-26T11:00:47.467833Z","iopub.execute_input":"2023-09-26T11:00:47.468177Z","iopub.status.idle":"2023-09-26T11:00:47.480409Z","shell.execute_reply.started":"2023-09-26T11:00:47.468145Z","shell.execute_reply":"2023-09-26T11:00:47.479166Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Freezing embeddings.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# MAP@3 Metric\nThe competition metric is MAP@3 therefore we will make a custom code to add to Hugging Face's trainer. Discussion [here][1]\n\n[1]: https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/435602","metadata":{}},{"cell_type":"code","source":"def map_at_3(predictions, labels):\n    map_sum = 0\n    pred = np.argsort(-1*np.array(predictions),axis=1)[:,:3]\n    for x,y in zip(pred,labels):\n        z = [1/i if y==j else 0 for i,j in zip([1,2,3],x)]\n        map_sum += np.sum(z)\n    return map_sum / len(predictions)\n\ndef compute_metrics(p):\n    predictions = p.predictions.tolist()\n    labels = p.label_ids.tolist()\n    return {\"map@3\": map_at_3(predictions, labels)}","metadata":{"execution":{"iopub.status.busy":"2023-09-26T11:00:47.481693Z","iopub.execute_input":"2023-09-26T11:00:47.482303Z","iopub.status.idle":"2023-09-26T11:00:47.491514Z","shell.execute_reply.started":"2023-09-26T11:00:47.482270Z","shell.execute_reply":"2023-09-26T11:00:47.490689Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Train and Save \nWe will now train and save our model using Hugging Face's easy to use trainer. By adjusting the parameters in this notebook, we can achieve `CV MAP@3 = 0.915+` and corresponding single model `LB MAP@3 = 0.830+` wow!\n\nIn we run this notebook outside of Kaggle then we can train longer and with more RAM. If we run this notebook on Kaggle, then we need to use tricks to train models efficiently. Here are some ideas:\n* use fp16 (this speeds up T4 not P100)\n* use gradient_accumlation_steps (this simulates larger batch sizes)\n* use gradient_checkpointing (this uses disk to save RAM)\n* use 2xT4 instead of 1xP100 (this doubles GPUs)\n* freeze model embeddings (this reduces weights to train)\n* freeze some model layers (this reduces weights to train)\n* use PEFT (this reduces weights to train)\n* increase LR and decrease epochs (this reduces work)\n* use smaller models (this reduces weights to train)","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    warmup_ratio=0.1, \n    learning_rate=3e-7,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=16,\n    num_train_epochs=1,\n   # fp16= True,\n    report_to='none',\n    output_dir = f'./checkpoints_{VER}',\n    overwrite_output_dir=True,\n    gradient_accumulation_steps=16,\n    logging_steps=25,\n    evaluation_strategy='steps',\n    eval_steps=25,\n    save_strategy=\"steps\",\n    save_steps=25,\n    load_best_model_at_end=False,\n    metric_for_best_model='map@3',\n    lr_scheduler_type='cosine',\n    weight_decay=0.001,\n    save_total_limit=4,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T11:00:47.492834Z","iopub.execute_input":"2023-09-26T11:00:47.493171Z","iopub.status.idle":"2023-09-26T11:00:47.532814Z","shell.execute_reply.started":"2023-09-26T11:00:47.493136Z","shell.execute_reply":"2023-09-26T11:00:47.531924Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n    train_dataset=tokenized_dataset,\n    eval_dataset=tokenized_dataset_valid,\n    compute_metrics = compute_metrics,\n    #callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n)\n\ntrainer.train()\ntrainer.save_model(f'model_v{VER}')","metadata":{"execution":{"iopub.status.busy":"2023-09-26T11:00:47.534074Z","iopub.execute_input":"2023-09-26T11:00:47.534713Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='203' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [203/250 1:29:17 < 20:52, 0.04 it/s, Epoch 0.81/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Map@3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>0.786500</td>\n      <td>0.668677</td>\n      <td>0.854027</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.702600</td>\n      <td>0.669951</td>\n      <td>0.854505</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.718100</td>\n      <td>0.670317</td>\n      <td>0.853391</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.689500</td>\n      <td>0.668748</td>\n      <td>0.854505</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.690100</td>\n      <td>0.668534</td>\n      <td>0.854982</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.732500</td>\n      <td>0.667913</td>\n      <td>0.855460</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.792400</td>\n      <td>0.668620</td>\n      <td>0.855301</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.654500</td>\n      <td>0.668950</td>\n      <td>0.855301</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"del model, trainer\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Verify Saved Model\nDuring training, we see the MAP@3 validation score above. Let's load the saved model and compute it again here to verify that our model is saved correctly.","metadata":{}},{"cell_type":"code","source":"del model, trainer\nif USE_PEFT:\n    model = AutoModelForMultipleChoice.from_pretrained(MODEL)\n    model = get_peft_model(model, peft_config)\n    checkpoint = torch.load(f'model_v{VER}/pytorch_model.bin')\n    model.load_state_dict(checkpoint)\nelse:\n    model = AutoModelForMultipleChoice.from_pretrained(f'model_v{VER}')\ntrainer = Trainer(model=model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/60k-data-with-context-v2/train_with_context2.csv')\ntokenized_test_dataset = Dataset.from_pandas(test_df).map(\n        preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E'])\n\ntest_predictions = trainer.predict(tokenized_test_dataset).predictions\npredictions_as_ids = np.argsort(-test_predictions, 1)\npredictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\npredictions_as_string = test_df['prediction'] = [\n    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute Validation Score","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/code/philippsinger/h2ogpt-perplexity-ranking\nimport numpy as np\ndef precision_at_k(r, k):\n    \"\"\"Precision at k\"\"\"\n    assert k <= len(r)\n    assert k != 0\n    return sum(int(x) for x in r[:k]) / k\n\ndef MAP_at_3(predictions, true_items):\n    \"\"\"Score is mean average precision at 3\"\"\"\n    U = len(predictions)\n    map_at_3 = 0.0\n    for u in range(U):\n        user_preds = predictions[u].split()\n        user_true = true_items[u]\n        user_results = [1 if item == user_true else 0 for item in user_preds]\n        for k in range(min(len(user_preds), 3)):\n            map_at_3 += precision_at_k(user_results, k+1) * user_results[k]\n    return map_at_3 / U","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = MAP_at_3(test_df.prediction.values, test_df.answer.values)\nprint( 'CV MAP@3 =',m )","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}